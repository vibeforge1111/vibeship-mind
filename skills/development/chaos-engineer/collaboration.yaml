# Chaos Engineer Collaboration Model
# How this skill works with other AI memory specialists

prerequisites:
  skills: []
  knowledge:
    - "Understanding of distributed systems"
    - "Basic Kubernetes concepts"
    - "Familiarity with monitoring concepts"
    - "Understanding of failure modes"

complementary_skills:
  - skill: infra-architect
    relationship: "Infrastructure resilience"
    brings: "Infrastructure failure modes, redundancy design"

  - skill: observability-sre
    relationship: "Chaos monitoring"
    brings: "Metrics, alerting, dashboards for experiments"

  - skill: test-architect
    relationship: "Chaos test integration"
    brings: "Test automation, CI/CD integration"

  - skill: performance-hunter
    relationship: "Performance under chaos"
    brings: "Performance baseline, degradation analysis"

  - skill: event-architect
    relationship: "Event system chaos"
    brings: "Kafka/NATS failure modes, partition tolerance"

  - skill: postgres-wizard
    relationship: "Database chaos"
    brings: "Database failure modes, replication testing"

delegation:
  - trigger: "infrastructure failure design"
    delegate_to: infra-architect
    pattern: parallel
    context: "Failure modes to test"
    receive: "Infrastructure redundancy recommendations"

  - trigger: "monitoring gaps"
    delegate_to: observability-sre
    pattern: sequential
    context: "Missing metrics for chaos experiments"
    receive: "New dashboards and alerts"

  - trigger: "CI/CD integration"
    delegate_to: test-architect
    pattern: parallel
    context: "Chaos in deployment pipeline"
    receive: "Automated chaos test setup"

  - trigger: "performance baseline"
    delegate_to: performance-hunter
    pattern: sequential
    context: "Need baseline for steady state"
    receive: "Performance metrics and thresholds"

  - trigger: "event queue chaos"
    delegate_to: event-architect
    pattern: parallel
    context: "Kafka/NATS failure scenarios"
    receive: "Event system chaos experiments"

  - trigger: "database failover"
    delegate_to: postgres-wizard
    pattern: parallel
    context: "Database failure scenarios"
    receive: "Database chaos experiments"

collaboration_patterns:
  sequential:
    - "I design experiment, then observability-sre verifies monitoring"
    - "I plan game day, then test-architect sets up automation"
    - "I find gap, then infra-architect designs fix"

  parallel:
    - "I run chaos while observability-sre monitors dashboards"
    - "I inject failure while performance-hunter measures impact"

  review:
    - "Review infra-architect's redundancy for chaos testability"
    - "Review observability-sre's alerts for chaos detection"
    - "Review test-architect's automation for chaos integration"

cross_domain_insights:
  - domain: safety-engineering
    insight: "Defense in depth: multiple barriers against failure"
    applies_when: "Designing failure cascade experiments"

  - domain: biology
    insight: "Antifragility: systems that grow stronger from stress"
    applies_when: "Explaining chaos engineering value"

  - domain: military
    insight: "War games reveal weaknesses before real battle"
    applies_when: "Planning game day exercises"

  - domain: psychology
    insight: "Practice under stress improves real performance"
    applies_when: "Training team on incident response"

  - domain: statistics
    insight: "Black swan events: rare but catastrophic"
    applies_when: "Prioritizing which failures to test"

ecosystem:
  primary_tools:
    - "LitmusChaos - Kubernetes chaos engineering"
    - "Chaos Monkey - Netflix's original chaos tool"
    - "Gremlin - Enterprise chaos platform"
    - "Chaos Mesh - Cloud-native chaos engineering"
    - "Toxiproxy - Network failure simulation"

  alternatives:
    - name: Pumba
      use_when: "Docker-based chaos, simple network simulation"
      avoid_when: "Need Kubernetes-native chaos"

    - name: PowerfulSeal
      use_when: "Need policy-based automated chaos"
      avoid_when: "Want experiment-based approach"

    - name: Chaos Toolkit
      use_when: "Want experiment-as-code approach"
      avoid_when: "Need UI and enterprise features"

    - name: AWS Fault Injection Simulator
      use_when: "AWS-only infrastructure"
      avoid_when: "Multi-cloud or on-prem"

  deprecated:
    - "Chaos without hypothesis"
    - "No kill switch in production chaos"
    - "Running chaos without team notification"
    - "Same chaos experiment without follow-up on findings"
    - "Chaos in production before staging"

# Mind v5 Specific Context
mind_v5_specific:
  primary_responsibility: Resilience testing for Mind v5 distributed system
  pod: platform
  critical_artifacts:
    - tests/chaos/*.yaml
    - deploy/k8s/litmus/*.yaml
  failure_domains:
    nats:
      experiments:
        - Consumer lag spike (partition loss)
        - Cluster leader election
        - Message replay during split-brain
      steady_state: "Event processing latency < 100ms p99"
    qdrant:
      experiments:
        - Node failure during search
        - Collection shard migration
        - Concurrent write/read during rebalance
      steady_state: "Vector search latency < 50ms p99"
    falkordb:
      experiments:
        - Connection pool exhaustion
        - Query timeout during graph traversal
      steady_state: "Graph query latency < 100ms p99"
    temporal:
      experiments:
        - Worker crash during workflow
        - Activity retry exhaustion
        - Workflow timeout and continuation
      steady_state: "Gardener workflows complete < error budget"
    postgres:
      experiments:
        - Primary failover to replica
        - Connection pool exhaustion
        - Long-running query kill
      steady_state: "Event store writes succeed 99.99%"
  game_day_scenarios:
    - name: "Memory Retrieval Under Fire"
      description: "Kill Qdrant node during decision support"
      hypothesis: "Retrieval gracefully degrades to cache"
    - name: "Event Backbone Partition"
      description: "NATS network partition between clusters"
      hypothesis: "Consumers resume from last checkpoint"
    - name: "Gardener Storm"
      description: "Mass workflow failures during discovery"
      hypothesis: "Temporal retries with backoff"
  metrics_owned:
    - mind_chaos_experiments_run_total
    - mind_chaos_steady_state_violations
    - mind_chaos_recovery_time_seconds
  delegation:
    - trigger: "infrastructure failure modes"
      delegate_to: infra-architect
      pattern: parallel
      context: "Components to test for resilience"
      receive: "Redundancy design and failure domain analysis"

    - trigger: "chaos experiment monitoring"
      delegate_to: observability-sre
      pattern: parallel
      context: "Metrics needed for steady state"
      receive: "Dashboards and alerts for chaos experiments"

    - trigger: "event system resilience"
      delegate_to: event-architect
      pattern: parallel
      context: "NATS failure scenarios"
      receive: "Consumer recovery patterns and replay safety"

    - trigger: "database failover testing"
      delegate_to: postgres-wizard
      pattern: parallel
      context: "PostgreSQL HA testing"
      receive: "Failover experiment design and recovery metrics"
